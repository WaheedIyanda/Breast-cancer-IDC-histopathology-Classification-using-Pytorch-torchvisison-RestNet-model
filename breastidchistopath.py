# -*- coding: utf-8 -*-
"""BreastIDCHistopath.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RzLTGqSfNVru-GumwCF6Hrb922vKlg9m
"""

#importing my libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import transforms
from torchvision import datasets
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image
import os

import cv2

#####dowload dataset
!kaggle datasets download -d alaminbhuyan/breast-histopathology-images

import zipfile
######
zip_file_path = 'breast-histopathology-images.zip'
extraction_dir = 'breast-histopathology-images'

#########
os.makedirs(extraction_dir, exist_ok=True)

#####Extracting file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_dir)

####extraction verification
extracted_files = os.listdir(extraction_dir)
print(extracted_files)

IDC_Neg = "/content/breast-histopathology-images/IDC_regular_ps50_idx5/negative_IDC"
IDC_pos = "/content/breast-histopathology-images/IDC_regular_ps50_idx5/positive_IDC"

#### function to check number of images in each folder
def count_images(directory):
    return len([f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])

#####
count_images(IDC_Neg)

count_images(IDC_pos)

num_neg = len(os.listdir(IDC_Neg))
num_pos = len(os.listdir(IDC_pos))

##### data distribution
categories = ['Negative IDC', 'Positive IDC']
counts = [num_neg, num_pos]

plt.figure(figsize=(8, 6))
plt.bar(categories, counts, color=['blue', 'orange'])
plt.title('image Distribution in IDC Categories')
plt.ylabel('Number of Images')
plt.xlabel('Categories')
plt.show()

#### image data inspection#
import random
selected_Neg = random.sample(os.listdir(IDC_Neg), 10)


plt.figure(figsize=(12, 8))
for i, file in enumerate(selected_Neg):
    img_path = os.path.join(IDC_Neg, file)
    img = Image.open(img_path)
    plt.subplot(2, 5, i + 1)
    plt.imshow(img)
    plt.axis('off')
plt.suptitle("Random Sample of Negative IDC Images", fontsize=16)
plt.show()

selected_pos = random.sample(os.listdir(IDC_pos), 10)

plt.figure(figsize=(12, 8))
for i, file in enumerate(selected_pos):
  imgs_path = os.path.join(IDC_pos, file)
  imgs= Image.open(imgs_path)
  plt.subplot(2, 5, i + 1)
  plt.imshow(imgs)
  plt.axis('off')

#####check dimension and color channel
def check_image_properties(directory, sample_size=5):
    files = os.listdir(directory)[:sample_size]
    for file in files:
        img_path = os.path.join(directory, file)
        with Image.open(img_path) as img:
            dimensions = img.size
            color_mode = img.mode
            channels = 1 if color_mode == 'L' else 3
            print(f'{file}: Dimensions={dimensions}, Channels={channels}')

### Confrim dimesion
print("Negative IDC Image Properties:")
check_image_properties(IDC_Neg)

print("\nPositive IDC Image Properties:")
check_image_properties(IDC_pos)

####spliting my data to Testing and Training data
from sklearn.model_selection import train_test_split

neg_files = [os.path.join(IDC_Neg, f) for f in os.listdir(IDC_Neg)]
pos_files = [os.path.join(IDC_pos, f) for f in os.listdir(IDC_pos)]

####labeling
neg_labels = [0] * len(neg_files)
pos_labels = [1] * len(pos_files)

all_files = neg_files + pos_files   ####this is our feature X
all_labels = neg_labels + pos_labels #### this is our target y

X_train, X_test, y_train, y_test = train_test_split(all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=42)

len(X_train) ###### number of traininf sample

len(y_train)

##### data processing
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

class HistoDataset(Dataset):
    def __init__(self, file_paths, labels, transform=None):
        self.file_paths = file_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        img_path = self.file_paths[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

train_dataset = HistoDataset(file_paths=X_train, labels=y_train, transform=transform)
test_dataset = HistoDataset(file_paths=X_test, labels=y_test, transform=transform)

####DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=4, pin_memory=True)

from torchvision import models

model = models.resnet18(pretrained=True)
num_classes = 2
model.fc = nn.Linear(model.fc.in_features, num_classes)

#####
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
#####
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

####

def train_model(model, train_loader, criterion, optimizer, epochs=3):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}")

# Training model###
train_model(model, train_loader, criterion, optimizer)

test_accuracy = evaluate_model(model, test_loader)
print(f'Test Accuracy: {test_accuracy:.2f}%')

import seaborn as sns

#####checking for accuracy
from sklearn.metrics import confusion_matrix
def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return all_preds, all_labels

# Get predictions and true labels
preds, labels = evaluate_model(model, test_loader)

# Compute confusion matrix
conf_matrix = confusion_matrix(labels, preds)

# Plot confusion matrix
plt.figure(figsize=(10,8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

torch.save(model.state_dict(), 'cancerHistopath.pth')
print("Model saved as 'model_state_dict.pth'")

